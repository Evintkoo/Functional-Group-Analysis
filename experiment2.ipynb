{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# general tools\n",
    "import numpy as np\n",
    "\n",
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_features(atom, \n",
    "                      use_chirality = True, \n",
    "                      hydrogens_implicit = False):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
    "    \n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    \n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    \n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    \n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    \n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    \n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    \n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "\n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "                                    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    \n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "\n",
    "    return np.array(atom_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_features(bond, \n",
    "                      use_stereochemistry = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n",
    "    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for (smiles, y_val) in tqdm(zip(x_smiles, y)):\n",
    "        \n",
    "        # convert SMILES to RDKit mol object\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        # get feature dimensions\n",
    "        n_nodes = mol.GetNumAtoms()\n",
    "        n_edges = 2*mol.GetNumBonds()\n",
    "        unrelated_smiles = \"O=O\"\n",
    "        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
    "        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
    "        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
    "\n",
    "        # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "        X = np.zeros((n_nodes, n_node_features))\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            X[atom.GetIdx(), :] = get_atom_features(atom)\n",
    "            \n",
    "        X = torch.tensor(X, dtype = torch.float)\n",
    "        \n",
    "        # construct edge index array E of shape (2, n_edges)\n",
    "        (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "        torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "        torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "        E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "        \n",
    "        # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "        EF = np.zeros((n_edges, n_edge_features))\n",
    "        \n",
    "        for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
    "            \n",
    "            EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j)))\n",
    "        \n",
    "        EF = torch.tensor(EF, dtype = torch.float)\n",
    "        \n",
    "        # construct label tensor\n",
    "        y_tensor = torch.tensor(np.array([y_val]), dtype = torch.float)\n",
    "        \n",
    "        # construct Pytorch Geometric data object and append to data list\n",
    "        data_list.append(Data(x = X, edge_index = E, edge_attr = EF, y = y_tensor))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "smiles = df[\"smiles\"]\n",
    "y = df[\"qed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "249455it [05:09, 806.36it/s] \n"
     ]
    }
   ],
   "source": [
    "geometric_graph = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(smiles,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 74)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size = (max([data.x.shape[0] for data in geometric_graph]), max([data.x.shape[1] for data in geometric_graph]))\n",
    "target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_center_tensor(tensor, target_rows, target_cols):\n",
    "    # Get the dimensions of the original tensor\n",
    "    original_rows, original_cols = tensor.shape\n",
    "    \n",
    "    # Calculate the padding needed to center the tensor\n",
    "    pad_top = (target_rows - original_rows) // 2\n",
    "    pad_bottom = target_rows - original_rows - pad_top\n",
    "    pad_left = (target_cols - original_cols) // 2\n",
    "    pad_right = target_cols - original_cols - pad_left\n",
    "    \n",
    "    # Pad the tensor with zeros to center it\n",
    "    padding = (pad_left, pad_right, pad_top, pad_bottom)  # (left, right, top, bottom)\n",
    "    centered_tensor = torch.nn.functional.pad(tensor, padding, mode='constant', value=0)\n",
    "    \n",
    "    return centered_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in geometric_graph:\n",
    "    data.x = resize_and_center_tensor(data.x, target_size[0], target_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(data.x).reshape(-1) for data in geometric_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model for tokenizing with specific input and output sizes using Sequential\n",
    "class TokenizerANN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        super(TokenizerANN, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  # First hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),       # Third hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),       # Fourth hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),        # Fifth hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size) ,\n",
    "            nn.Softmax()# Encoder output layer\n",
    "        )\n",
    "       \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_size, 64),          # Decoder input layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),        # First hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),       # Second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),       # Third hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_size)   # Decoder output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 32, 128]         360,064\n",
      "              ReLU-2              [-1, 32, 128]               0\n",
      "            Linear-3              [-1, 32, 128]          16,512\n",
      "              ReLU-4              [-1, 32, 128]               0\n",
      "            Linear-5              [-1, 32, 128]          16,512\n",
      "              ReLU-6              [-1, 32, 128]               0\n",
      "            Linear-7               [-1, 32, 64]           8,256\n",
      "              ReLU-8               [-1, 32, 64]               0\n",
      "            Linear-9                [-1, 32, 4]             260\n",
      "          Softmax-10                [-1, 32, 4]               0\n",
      "           Linear-11               [-1, 32, 64]             320\n",
      "             ReLU-12               [-1, 32, 64]               0\n",
      "           Linear-13              [-1, 32, 128]           8,320\n",
      "             ReLU-14              [-1, 32, 128]               0\n",
      "           Linear-15              [-1, 32, 128]          16,512\n",
      "             ReLU-16              [-1, 32, 128]               0\n",
      "           Linear-17              [-1, 32, 128]          16,512\n",
      "             ReLU-18              [-1, 32, 128]               0\n",
      "           Linear-19             [-1, 32, 2812]         362,748\n",
      "================================================================\n",
      "Total params: 806,016\n",
      "Trainable params: 806,016\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.34\n",
      "Forward/backward pass size (MB): 1.13\n",
      "Params size (MB): 3.07\n",
      "Estimated Total Size (MB): 4.54\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Evint\\Documents\\Projects\\Functional-Group-Analysis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "batch_size = 32\n",
    "target_size = 4\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, X, \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.4,  \n",
    "                                   shuffle=True) \n",
    "\n",
    "tensor_X_train = torch.from_numpy(X_train).to(device)\n",
    "tensor_X_test = torch.from_numpy(X_test).to(device)\n",
    "tensor_y_train = torch.from_numpy(y_train).to(device)\n",
    "tensor_y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = TokenizerANN(input_size = tensor_X_test.shape[1],\n",
    "                     output_size=target_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# define history list\n",
    "class history:\n",
    "    def __init__(self) -> None:\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.metric_loss = []\n",
    "        self.val_metric_loss = []\n",
    "h = history()\n",
    "\n",
    "summary(model, (batch_size, tensor_X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evint\\AppData\\Local\\Temp\\ipykernel_6624\\3269103128.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(inputs, dtype=torch.float32))\n",
      "C:\\Users\\Evint\\AppData\\Local\\Temp\\ipykernel_6624\\3269103128.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_outputs = model(torch.tensor(tensor_X_test, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.0162; val_loss: 0.0150 saved\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.05 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(loss_acc)\n\u001b[0;32m     13\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(tensor_X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m---> 14\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_y_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_loss \u001b[38;5;241m>\u001b[39m epoch_loss:\n",
      "File \u001b[1;32mc:\\Users\\Evint\\Documents\\Projects\\Functional-Group-Analysis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Evint\\Documents\\Projects\\Functional-Group-Analysis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Evint\\Documents\\Projects\\Functional-Group-Analysis\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Evint\\Documents\\Projects\\Functional-Group-Analysis\\venv\\lib\\site-packages\\torch\\nn\\functional.py:3366\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3363\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3365\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.05 GiB. GPU "
     ]
    }
   ],
   "source": [
    "\n",
    "min_loss = 1e5\n",
    "for epoch in range(num_epochs):\n",
    "    loss_acc = []\n",
    "    for inputs, targets in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(inputs, dtype=torch.float32))\n",
    "        loss = criterion(outputs, targets.to(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_acc.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(loss_acc)\n",
    "    val_outputs = model(torch.tensor(tensor_X_test, dtype=torch.float32))\n",
    "    val_loss = criterion(val_outputs, tensor_y_test)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}; val_loss: {val_loss:.4f}\", end=\" \")\n",
    "    if min_loss > epoch_loss:\n",
    "        torch.save(model.state_dict(), \"tokenizer_ann_with_decoder.pth\")\n",
    "        min_loss = epoch_loss\n",
    "        print(\"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
